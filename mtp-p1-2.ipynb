{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import UpSampling2D\nfrom tensorflow.keras.layers import concatenate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = \"/kaggle/input/mtp-phase1/input/input/\"\nmask_path = \"/kaggle/input/mtp-phase1/target/target/\"\nimage_list_orig = os.listdir(image_path)\nmask_list_orig = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list_orig]\nmask_list = [mask_path+i for i in mask_list_orig]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\nmask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n    print(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_filenames = tf.constant(image_list)\nmasks_filenames = tf.constant(mask_list)\n\ndataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n\nfor image, mask in dataset.take(1):\n    print(image)\n    print(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_path(image_path, mask_path):\n#     img = tf.io.read_file(image_path)\n#     img = tf.image.decode_png(image, channels=1, dtype=tf.float32)\n# #     img = img / 255.0\n\n#     mask = tf.io.read_file(mask_path)\n#     mask = tf.image.decode_png(mask, channels=1)\n#     mask= mask/255\n    # mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img, channels=1)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=1)\n    mask= mask/255\n    return img, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ds = dataset.map(process_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i1= image_ds.take(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        print(display_list[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, mask in image_ds.take(2):\n    sample_image, sample_mask = image, mask\n    print(mask.shape)\ndisplay([sample_image, sample_mask])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNQ_C1\n# GRADED FUNCTION: conv_block\ndef conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \"\"\"\n    Convolutional downsampling block\n    \n    Arguments:\n        inputs -- Input tensor\n        n_filters -- Number of filters for the convolutional layers\n        dropout_prob -- Dropout probability\n        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n    Returns: \n        next_layer, skip_connection --  Next layer and skip connection outputs\n    \"\"\"\n\n    ### START CODE HERE\n    conv = Conv2D(n_filters, # Number of filters\n                  (3,3),   # Kernel size   \n                  activation= 'relu',\n                  padding= 'same',\n                  kernel_initializer='he_normal')(inputs)\n    conv = Conv2D(n_filters, # Number of filters\n                  (3,3),   # Kernel size\n                  activation= 'relu',\n                  padding= 'same',\n                  # set 'kernel_initializer' same as above\n                  kernel_initializer= 'he_normal')(conv)\n    ### END CODE HERE\n    \n    input_shape= inputs.shape\n#     print(input_shape)\n    extra_channels= n_filters- input_shape[-1]\n#     #zeros_channels = np.zeros((input_shape[0], input_shape[1], extra_channels))\n    zeros_channels = tf.zeros([tf.shape(inputs)[0], input_shape[1], input_shape[2], extra_channels], dtype=tf.float32)\n    inputs_padded= tf.concat([inputs, zeros_channels], axis=-1)\n    \n    conv= inputs_padded + conv\n    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n    \n    if dropout_prob > 0:\n         ### START CODE HERE\n        conv = Dropout(dropout_prob)(conv)\n         ### END CODE HERE\n         \n        \n    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n    if max_pooling:\n        ### START CODE HERE\n        next_layer = MaxPooling2D((2, 2))(conv)\n        ### END CODE HERE\n        \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNQ_C2\n# GRADED FUNCTION: upsampling_block\ndef upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \"\"\"\n    Convolutional upsampling block\n    \n    Arguments:\n        expansive_input -- Input tensor from previous layer\n        contractive_input -- Input tensor from previous skip layer\n        n_filters -- Number of filters for the convolutional layers\n    Returns: \n        conv -- Tensor output\n    \"\"\"\n    \n    ### START CODE HERE\n    up = UpSampling2D(size=(2, 2),interpolation='bilinear')(expansive_input)\n    \n    # Merge the previous output and the contractive_input\n    merge = concatenate([up, contractive_input], axis=3)\n    conv = Conv2D(n_filters,   # Number of filters\n                 3,     # Kernel size\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(merge)\n    conv = Conv2D(n_filters,  # Number of filters\n                 3,   # Kernel size\n                 activation='relu',\n                 padding='same',\n                  # set 'kernel_initializer' same as above\n                 kernel_initializer='he_normal')(conv)\n    ### END CODE HERE\n    \n    return conv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNQ_C3\n# GRADED FUNCTION: unet_model\ndef unet_model(input_size=(400, 400, 1), n_filters=32, n_classes=1):\n    \"\"\"\n    Unet model\n    \n    Arguments:\n        input_size -- Input shape \n        n_filters -- Number of filters for the convolutional layers\n        n_classes -- Number of output classes\n    Returns: \n        model -- tf.keras.Model\n    \"\"\"\n    inputs = Input(input_size)\n    # Contracting Path (encoding)\n    # Add a conv_block with the inputs of the unet_ model and n_filters\n    ### START CODE HERE\n    cblock1 = conv_block(inputs, n_filters)\n    # Chain the first element of the output of each block to be the input of the next conv_block. \n    # Double the number of filters at each new step\n    cblock2 = conv_block(cblock1[0], 2*n_filters)\n    cblock3 = conv_block(cblock2[0], 4*n_filters)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, 0.3) # Include a dropout_prob of 0.3 for this layer\n    # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n#     cblock5 = conv_block(cblock4[0], 16*n_filters, 0.3, max_pooling= False) \n    ### END CODE HERE\n    cblock5 = Conv2D(8*n_filters, # Number of filters\n                  (3,3),   # Kernel size   \n                  activation= 'relu',\n                  padding= 'same',\n                  kernel_initializer='he_normal')(cblock4[0])\n    # Expanding Path (decoding)\n    # Add the first upsampling_block.\n    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n    ### START CODE HERE\n    ublock6 = upsampling_block(cblock5, cblock4[1],  8*n_filters)\n    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n    # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n    # At each step, use half the number of filters of the previous block \n    ublock7 = upsampling_block(ublock6, cblock3[1],  4*n_filters)\n    ublock8 = upsampling_block(ublock7, cblock2[1],  2*n_filters)\n    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n    ### END CODE HERE\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 # set 'kernel_initializer' same as above exercises\n                 kernel_initializer='he_normal')(ublock9)\n\n    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n    ### START CODE HERE\n    conv10 = Conv2D(n_classes, 1, activation='sigmoid', padding='same')(conv9)\n    ### END CODE HERE\n    \n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet= unet_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss= tf.keras.losses.MeanAbsoluteError())","metadata":{"execution":{"iopub.status.busy":"2023-10-30T20:58:27.657761Z","iopub.execute_input":"2023-10-30T20:58:27.658094Z","iopub.status.idle":"2023-10-30T20:58:27.675780Z","shell.execute_reply.started":"2023-10-30T20:58:27.658062Z","shell.execute_reply":"2023-10-30T20:58:27.674890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 500\nBATCH_SIZE = 32\ntrain_dataset = image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(image_ds.element_spec)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T20:58:37.370397Z","iopub.execute_input":"2023-10-30T20:58:37.370773Z","iopub.status.idle":"2023-10-30T20:58:37.389165Z","shell.execute_reply.started":"2023-10-30T20:58:37.370742Z","shell.execute_reply":"2023-10-30T20:58:37.388195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = unet.fit(train_dataset, epochs=1000)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T20:58:39.567120Z","iopub.execute_input":"2023-10-30T20:58:39.567834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, m in image_ds.take(1):\n    pred_mask = unet.predict(i[tf.newaxis,...])\n    print(pred_mask[0])\n    display([i, m,pred_mask[0]])","metadata":{},"execution_count":null,"outputs":[]}]}